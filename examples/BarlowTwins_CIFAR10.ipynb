{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd933ab8",
   "metadata": {},
   "source": [
    "# [BarlowTwins](https://arxiv.org/abs/2103.03230) on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c5bf3b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlr_scheduler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CosineAnnealingLR\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resnet18\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BarlowTwins\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#from optimizer import LARS\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SSL_Trainer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "from os import makedirs\n",
    "\n",
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from models import BarlowTwins\n",
    "#from optimizer import LARS\n",
    "from trainer import SSL_Trainer\n",
    "from utils import SSL_CIFAR10\n",
    "\n",
    "# Define hyperparameters\n",
    "data_root = './data/'\n",
    "save_root = './results/barlow_twins/'\n",
    "\n",
    "dl_kwargs = {'batch_size': 512, 'shuffle': True, 'num_workers': 2}\n",
    "\n",
    "# Define data\n",
    "ssl_data = SSL_CIFAR10(data_root,'BYOL', dl_kwargs)\n",
    "\n",
    "# general training params\n",
    "train_params = {'save_root': save_root, 'num_epochs': 800, 'optimizer': SGD,\n",
    "                'scheduler': CosineAnnealingLR, 'warmup_epochs': 10, 'iter_scheduler':True,\n",
    "                'evaluate_at': [1,50,100,200,400,600], 'verbose':True}\n",
    "\n",
    "# params of optimizer\n",
    "## In Original Paper for Imagenet when using LARS Optimizer\n",
    "#optim_params = {'lr':0.2 * dl_kwargs['batch_size']/256, 'weight_decay': 1.5e-6,\n",
    "#                'exclude_bias_and_norm': True}\n",
    "\n",
    "# from: https://docs.lightly.ai/getting_started/benchmarks.html#cifar10\n",
    "optim_params = {'lr': 6e-2, 'momentum': 0.9, 'weight_decay': 5e-4} \n",
    "\n",
    "# params of scheduler\n",
    "scheduler_params = {'T_max': (train_params['num_epochs']-train_params['warmup_epochs'])*len(ssl_data.train_dl)}\n",
    "                    # 'eta_min': 1e-3} in orginal implementation\n",
    "\n",
    "# Set parameters for fitting linear protocoler\n",
    "eval_params  = {'lr':1e-2, 'num_epochs': 25, 'milestones': [12,20]}\n",
    "\n",
    "# Get device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Print Device Type\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Program running on {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    print(\"Program running on CPU\")\n",
    "    \n",
    "# Create folder if it does not exists\n",
    "makedirs(save_root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7fa78",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04393c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "resnet = resnet18(zero_init_residual=True)\n",
    "# Cifar specifics\n",
    "resnet.conv1 = torch.nn.Conv2d(3,64, 3, 1, 1, bias=False)\n",
    "resnet.maxpool = torch.nn.Identity()\n",
    "\n",
    "model = BarlowTwins(resnet, projector_hidden = (2048,2048,2048))\n",
    "\n",
    "# Define Trainer\n",
    "cifar10_trainer = SSL_Trainer(model, ssl_data, device)\n",
    "\n",
    "# Train\n",
    "cifar10_trainer.train(**train_params, optim_params=optim_params,\n",
    "                      scheduler_params=scheduler_params, eval_params=eval_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43ed0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741c57a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3ef17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4ba4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TorchSSL)",
   "language": "python",
   "name": "torchssl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
