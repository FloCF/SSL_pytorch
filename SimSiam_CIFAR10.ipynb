{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd933ab8",
   "metadata": {},
   "source": [
    "# [SimSiam](https://arxiv.org/abs/2011.10566) on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4920ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Program running on NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "from os import makedirs\n",
    "\n",
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from models import SimSiam\n",
    "from trainer import SSL_Trainer\n",
    "from utils import SSL_CIFAR10\n",
    "\n",
    "# Define hyperparameters\n",
    "data_root = '/home/space/datasets/'\n",
    "#data_root = '/home/fcfschulz/Documents/workspace/data/Vision/'\n",
    "save_root = './results/simsiam/'\n",
    "\n",
    "dl_kwargs = {'batch_size': 512, 'shuffle': True, 'num_workers': 2}\n",
    "\n",
    "# Define data\n",
    "ssl_data = SSL_CIFAR10(data_root,'SimSiam', dl_kwargs)\n",
    "\n",
    "# general training params\n",
    "train_params = {'save_root': save_root, 'num_epochs': 15, 'optimizer': SGD,\n",
    "                'scheduler': CosineAnnealingLR, 'warmup_epochs': 10, 'iter_scheduler':True,\n",
    "                'evaluate_at': [100,200,400,600], 'verbose':True}\n",
    "\n",
    "# params of optimizer\n",
    "# From original paper\n",
    "optim_params = {'lr':0.03 * dl_kwargs['batch_size']/256,\n",
    "                'weight_decay': 5e-4,\n",
    "                'momentum' : 0.9}\n",
    "\n",
    "# params of scheduler\n",
    "scheduler_params = {'T_max': (train_params['num_epochs']-train_params['warmup_epochs'])*len(ssl_data.train_dl)}\n",
    "                    # 'eta_min':1e-4} in orginal implementation\n",
    "\n",
    "# Set parameters for fitting linear protocoler\n",
    "eval_params  = {'lr':1e-2, 'num_epochs': 5, 'milestones': [12,20]}\n",
    "\n",
    "# Get device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Print Device Type\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Program running on {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    print(\"Program running on CPU\")\n",
    "    \n",
    "# Create folder if it does not exists\n",
    "makedirs(save_root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7fa78",
   "metadata": {},
   "source": [
    "# SimSiam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee883c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fcfschulz/miniconda3/envs/pg_high/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.9814488555967193, Time epoch: 187.97060108184814\n",
      "Epoch: 1, Loss: 0.8999253001409707, Time epoch: 203.1080060005188\n",
      "Epoch: 2, Loss: 0.7540117293289027, Time epoch: 200.95217490196228\n",
      "Epoch: 3, Loss: 0.6343861074791741, Time epoch: 202.13703632354736\n",
      "Epoch: 4, Loss: 0.5814269277238354, Time epoch: 203.0395324230194\n",
      "Epoch: 5, Loss: 0.5513902030040309, Time epoch: 200.9306755065918\n",
      "Epoch: 6, Loss: 0.5281851998309499, Time epoch: 199.75597286224365\n",
      "Epoch: 7, Loss: 0.5052382638773967, Time epoch: 198.20007419586182\n",
      "Epoch: 8, Loss: 0.47937036851017745, Time epoch: 205.35928893089294\n",
      "Epoch: 9, Loss: 0.4586545290406217, Time epoch: 207.7198724746704\n",
      "Epoch: 10, Loss: 0.443931519985199, Time epoch: 208.11708688735962\n"
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "resnet = resnet18(zero_init_residual=True)\n",
    "\n",
    "simsiam = SimSiam(resnet,\n",
    "                  projector_hidden = (2048, 2048),\n",
    "                  predictor_hidden = (512, 2048))\n",
    "\n",
    "# Define Trainer\n",
    "cifar10_trainer = SSL_Trainer(simsiam, ssl_data, device)\n",
    "\n",
    "# Train\n",
    "cifar10_trainer.train(**train_params, optim_params=optim_params,\n",
    "                      scheduler_params=scheduler_params, eval_params=eval_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3ef17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4ba4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pg_high)",
   "language": "python",
   "name": "pg_high"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
